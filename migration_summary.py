#!/usr/bin/env python3
"""
Migration Summary for C2PUML Test Framework

This script creates a readable summary of the migration recommendations
generated by todo_recommendations.py and provides specific action items
for each test file.
"""

import json
from pathlib import Path
from collections import defaultdict

def load_recommendations():
    """Load the recommendations from JSON file"""
    with open("todo_recommendations.json", 'r') as f:
        return json.load(f)

def print_executive_summary(data):
    """Print executive summary"""
    metadata = data["analysis_metadata"]
    
    print("="*80)
    print("C2PUML TEST MIGRATION - EXECUTIVE SUMMARY")
    print("="*80)
    print(f"ğŸ“‹ Total Files Analyzed: {metadata['total_files_analyzed']}")
    print(f"ğŸ”´ High Priority: {metadata['high_priority_count']} files")
    print(f"ğŸŸ¡ Medium Priority: {metadata['medium_priority_count']} files") 
    print(f"ğŸŸ¢ Low Priority: {metadata['low_priority_count']} files")
    print()
    print(f"ğŸ“ Data JSON Strategy: {metadata['data_json_strategy_count']} files")
    print(f"ğŸ“„ Explicit Files Strategy: {metadata['explicit_files_strategy_count']} files")
    print(f"âœ‚ï¸ Files Requiring Split: {metadata['split_required_count']} files")

def print_critical_findings(recommendations):
    """Print critical findings that need immediate attention"""
    print("\n" + "="*80)
    print("âš ï¸ CRITICAL FINDINGS")
    print("="*80)
    
    # Files that need splitting
    split_files = [r for r in recommendations if r['analysis']['should_split']]
    if split_files:
        print(f"\nğŸš¨ {len(split_files)} LARGE FILES REQUIRE SPLITTING:")
        for rec in split_files:
            file_name = Path(rec['original_file']).name
            methods = rec['analysis']['total_methods']
            suggestions = rec['analysis']['split_suggestions']
            print(f"   â€¢ {file_name}: {methods} methods â†’ split into {len(suggestions)} files")
            for suggestion in suggestions[:3]:  # Show first 3 suggestions
                print(f"     - {suggestion}")
            if len(suggestions) > 3:
                print(f"     - ... and {len(suggestions) - 3} more")
    
    # High complexity files
    complex_files = [r for r in recommendations 
                    if r['analysis']['total_methods'] > 20 and r['estimated_effort'] == 'high']
    if complex_files:
        print(f"\nğŸ”¥ {len(complex_files)} HIGH COMPLEXITY FILES:")
        for rec in sorted(complex_files, key=lambda x: x['analysis']['total_methods'], reverse=True)[:5]:
            file_name = Path(rec['original_file']).name
            methods = rec['analysis']['total_methods']
            strategy = rec['analysis']['recommended_strategy']
            print(f"   â€¢ {file_name}: {methods} methods, {strategy} strategy")

def print_strategy_breakdown(recommendations):
    """Print detailed strategy breakdown"""
    print("\n" + "="*80)
    print("ğŸ“Š STRATEGY BREAKDOWN")
    print("="*80)
    
    # Group by strategy
    strategies = defaultdict(list)
    for rec in recommendations:
        strategy = rec['analysis']['recommended_strategy']
        strategies[strategy].append(rec)
    
    for strategy, files in strategies.items():
        print(f"\nğŸ“ {strategy.upper().replace('_', ' ')} ({len(files)} files):")
        
        # Sort by priority and method count
        sorted_files = sorted(files, key=lambda x: (
            0 if x['analysis']['priority'] == 'high' else 1 if x['analysis']['priority'] == 'medium' else 2,
            -x['analysis']['total_methods']
        ))
        
        for rec in sorted_files[:10]:  # Show top 10
            file_name = Path(rec['original_file']).name
            methods = rec['analysis']['total_methods']
            priority = rec['analysis']['priority']
            category = rec['analysis']['category']
            print(f"   â€¢ {file_name} [{category}]: {methods} methods, {priority} priority")

def print_migration_phases(recommendations):
    """Print recommended migration phases"""
    print("\n" + "="*80)
    print("ğŸš€ RECOMMENDED MIGRATION PHASES")
    print("="*80)
    
    # Phase 1: High priority, low effort
    phase1 = [r for r in recommendations 
             if r['analysis']['priority'] == 'high' and r['estimated_effort'] in ['low', 'medium']]
    
    # Phase 2: High priority, high effort (split or keep)
    phase2 = [r for r in recommendations 
             if r['analysis']['priority'] == 'high' and r['estimated_effort'] == 'high']
    
    # Phase 3: Medium priority
    phase3 = [r for r in recommendations if r['analysis']['priority'] == 'medium']
    
    # Phase 4: Low priority
    phase4 = [r for r in recommendations if r['analysis']['priority'] == 'low']
    
    print(f"\nğŸ¯ PHASE 1 - Quick Wins ({len(phase1)} files)")
    print("   High priority, manageable effort")
    for rec in sorted(phase1, key=lambda x: x['analysis']['total_methods'])[:8]:
        file_name = Path(rec['original_file']).name
        methods = rec['analysis']['total_methods']
        strategy = rec['analysis']['recommended_strategy']
        print(f"   â€¢ {file_name}: {methods} methods, {strategy}")
    
    print(f"\nğŸ”¥ PHASE 2 - Major Refactoring ({len(phase2)} files)")
    print("   High priority, high effort - consider splitting")
    for rec in sorted(phase2, key=lambda x: x['analysis']['total_methods'], reverse=True)[:5]:
        file_name = Path(rec['original_file']).name
        methods = rec['analysis']['total_methods']
        should_split = rec['analysis']['should_split']
        split_indicator = " [SPLIT]" if should_split else ""
        print(f"   â€¢ {file_name}: {methods} methods{split_indicator}")
    
    print(f"\nâ³ PHASE 3 - Medium Priority ({len(phase3)} files)")
    print(f"âš¡ PHASE 4 - Low Priority ({len(phase4)} files)")

def print_specific_recommendations():
    """Print specific file-by-file recommendations"""
    print("\n" + "="*80)
    print("ğŸ“‹ TOP 10 SPECIFIC RECOMMENDATIONS")
    print("="*80)
    
    recommendations = [
        {
            "file": "test_transformer.py",
            "methods": 80,
            "action": "SPLIT into 5-6 files by functionality (renaming, removal, addition, etc.)",
            "structure": "Use data_transformation_*.json for each operation type",
            "priority": "ğŸ”´ CRITICAL"
        },
        {
            "file": "test_tokenizer.py", 
            "methods": 41,
            "action": "SPLIT into token types (keywords, identifiers, operators, etc.)",
            "structure": "Use data_tokenize_*.json for each token category",
            "priority": "ğŸ”´ CRITICAL"
        },
        {
            "file": "test_parser_comprehensive.py",
            "methods": 36,
            "action": "SPLIT into 7 focused test files by C language construct",
            "structure": "data_struct_parsing.json, data_enum_parsing.json, etc.",
            "priority": "ğŸ”´ CRITICAL"
        },
        {
            "file": "test_generator.py",
            "methods": 20,
            "action": "Use data_generation_*.json for different output scenarios",
            "structure": "data_basic_generation.json, data_complex_generation.json",
            "priority": "ğŸ”´ HIGH"
        },
        {
            "file": "test_preprocessor_bug.py",
            "methods": 19,
            "action": "Use data_preprocessor_*.json for different directive types",
            "structure": "data_ifdef.json, data_define.json, data_include.json",
            "priority": "ğŸ”´ HIGH"
        },
        {
            "file": "test_invalid_source_paths.py",
            "methods": 17,
            "action": "Use data_path_error_*.json for different error scenarios",
            "structure": "data_missing_files.json, data_invalid_paths.json",
            "priority": "ğŸ”´ HIGH"
        },
        {
            "file": "test_preprocessor_handling.py",
            "methods": 14,
            "action": "Use data_preprocessor_handling_*.json by directive type",
            "structure": "Group by conditional compilation, macro expansion",
            "priority": "ğŸ”´ HIGH"
        },
        {
            "file": "test_anonymous_processor_extended.py",
            "methods": 14,
            "action": "Use data_anonymous_*.json for complexity levels",
            "structure": "data_simple_anonymous.json, data_nested_anonymous.json",
            "priority": "ğŸ”´ HIGH"
        },
        {
            "file": "test_config.py",
            "methods": 13,
            "action": "Use data_config_*.json for different config scenarios",
            "structure": "data_basic_config.json, data_advanced_config.json",
            "priority": "ğŸŸ¡ MEDIUM"
        },
        {
            "file": "test_include_filtering_bugs.py",
            "methods": 12,
            "action": "Use data_include_filter_*.json for filter patterns",
            "structure": "data_include_patterns.json, data_exclude_patterns.json",
            "priority": "ğŸŸ¡ MEDIUM"
        }
    ]
    
    for i, rec in enumerate(recommendations, 1):
        print(f"\n{i:2d}. {rec['priority']} {rec['file']}")
        print(f"    ğŸ“Š Methods: {rec['methods']}")
        print(f"    ğŸ¯ Action: {rec['action']}")
        print(f"    ğŸ“ Structure: {rec['structure']}")

def print_data_json_examples():
    """Print examples of data.json structures for different scenarios"""
    print("\n" + "="*80)
    print("ğŸ“ DATA.JSON EXAMPLES BY USE CASE")
    print("="*80)
    
    examples = {
        "Simple Struct Parsing": {
            "file": "data_simple_struct.json",
            "content": {
                "description": "Basic struct parsing test",
                "generate_type": "source_files",
                "files": {
                    "test.c": {
                        "content": "#include <stdio.h>\n\nstruct Point {\n    int x;\n    int y;\n};\n\nint main() {\n    struct Point p = {10, 20};\n    return 0;\n}"
                    }
                },
                "expected_elements": {
                    "structs": ["Point"],
                    "functions": ["main"]
                }
            }
        },
        "Preprocessor Conditional": {
            "file": "data_ifdef_test.json", 
            "content": {
                "description": "Conditional compilation test",
                "generate_type": "source_files",
                "files": {
                    "conditional.c": {
                        "content": "#ifdef DEBUG\n#define LOG(x) printf(x)\n#else\n#define LOG(x)\n#endif\n\nint main() {\n    LOG(\"Debug mode\");\n    return 0;\n}"
                    }
                },
                "config_overrides": {
                    "preprocessor_defines": ["DEBUG"]
                }
            }
        },
        "Complex Transformation": {
            "file": "data_rename_functions.json",
            "content": {
                "description": "Function renaming transformation test",
                "generate_type": "model_json",
                "model": {
                    "files": {
                        "main.c": {
                            "functions": [
                                {"name": "deprecated_init", "return_type": "void"},
                                {"name": "old_cleanup", "return_type": "void"}
                            ]
                        }
                    }
                },
                "config_overrides": {
                    "transformations": {
                        "rename": {
                            "functions": {
                                "^deprecated_(.*)": "legacy_\\1",
                                "^old_(.*)": "legacy_\\1"
                            }
                        }
                    }
                }
            }
        }
    }
    
    for title, example in examples.items():
        print(f"\nğŸ“„ {title} ({example['file']}):")
        content = json.dumps(example['content'], indent=2)
        # Show first few lines
        lines = content.split('\n')
        for line in lines[:15]:
            print(f"   {line}")
        if len(lines) > 15:
            print(f"   ... ({len(lines) - 15} more lines)")

def print_folder_structure_examples():
    """Print examples of recommended folder structures"""
    print("\n" + "="*80)
    print("ğŸ“ FOLDER STRUCTURE EXAMPLES")
    print("="*80)
    
    structures = [
        {
            "title": "Simple Test (Single Input)",
            "example": "test_generator_duplicate_includes",
            "structure": [
                "test_generator_duplicate_includes/",
                "â”œâ”€â”€ test_generator_duplicate_includes.py",
                "â”œâ”€â”€ input/",
                "â”‚   â”œâ”€â”€ config.json",
                "â”‚   â”œâ”€â”€ main.c",
                "â”‚   â”œâ”€â”€ utils.h",
                "â”‚   â””â”€â”€ types.h",
                "â””â”€â”€ assertions.json"
            ]
        },
        {
            "title": "Multiple Scenarios (Data JSON)",
            "example": "test_parser_filtering",
            "structure": [
                "test_parser_filtering/",
                "â”œâ”€â”€ test_parser_filtering.py", 
                "â”œâ”€â”€ input/",
                "â”‚   â”œâ”€â”€ config.json",
                "â”‚   â”œâ”€â”€ data_include_patterns.json",
                "â”‚   â”œâ”€â”€ data_exclude_patterns.json",
                "â”‚   â””â”€â”€ data_mixed_filters.json",
                "â””â”€â”€ assertions.json"
            ]
        },
        {
            "title": "Split Large Test",
            "example": "test_parser_comprehensive â†’ split",
            "structure": [
                "test_struct_parsing/",
                "â”œâ”€â”€ test_struct_parsing.py",
                "â”œâ”€â”€ input/",
                "â”‚   â”œâ”€â”€ config.json",
                "â”‚   â”œâ”€â”€ data_simple_struct.json",
                "â”‚   â”œâ”€â”€ data_nested_struct.json",
                "â”‚   â””â”€â”€ data_anonymous_struct.json",
                "â””â”€â”€ assertions.json",
                "",
                "test_enum_parsing/",
                "â”œâ”€â”€ test_enum_parsing.py",
                "â”œâ”€â”€ input/",
                "â”‚   â”œâ”€â”€ config.json",
                "â”‚   â”œâ”€â”€ data_simple_enum.json",
                "â”‚   â””â”€â”€ data_typedef_enum.json",
                "â””â”€â”€ assertions.json",
                "",
                "... (5 more split test folders)"
            ]
        }
    ]
    
    for struct in structures:
        print(f"\nğŸ“‚ {struct['title']} - {struct['example']}")
        for line in struct['structure']:
            if line:
                print(f"   {line}")
            else:
                print()

def main():
    """Main function"""
    try:
        data = load_recommendations()
        recommendations = data["recommendations"]
        
        print_executive_summary(data)
        print_critical_findings(recommendations)
        print_strategy_breakdown(recommendations)
        print_migration_phases(recommendations)
        print_specific_recommendations()
        print_data_json_examples()
        print_folder_structure_examples()
        
        print("\n" + "="*80)
        print("âœ… NEXT STEPS")
        print("="*80)
        print("1. ğŸ—ï¸  Implement TestDataFactory with data.json support")
        print("2. ğŸ”§ Create TestExecutor for CLI-only testing")
        print("3. âœ… Create validation framework (ModelValidator, etc.)")
        print("4. ğŸš€ Start with Phase 1 files (quick wins)")
        print("5. âœ‚ï¸  Plan splitting strategy for large files")
        print("6. ğŸ“Š Track progress in todo.md file")
        print()
        print("ğŸ“‹ See todo_recommendations.json for complete details")
        print("="*80)
        
    except FileNotFoundError:
        print("âŒ Error: todo_recommendations.json not found!")
        print("Run python3 todo_recommendations.py first to generate recommendations.")

if __name__ == "__main__":
    main()